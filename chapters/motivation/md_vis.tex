
\section{Visualizing multi-dimensional continuous spaces}
\label{sec:multi-d-challenges}

Understanding multi-dimensional space is difficult. As humans, we simply do not
have the spatial analogs in more than three dimensions. A number of methods
have been developed to extract specific features from the multi-dimensional
object. For example, when studying polytopes, the number of faces and
symmetries is very important~\cite{Ziegler:2012}. However, these only produce
an answer without sufficient context. They do not necessarily give any
intuition as to how to transfer our three-dimensional knowledge to
multi-dimensional spaces.

%\ttwnote{how visualization can help}
%\ttwnote{some sort of insight generation from context?}

Visualizations of multi-dimensional spaces on a 2D screen must contend with
some sort of reduction of the information. A proper visualization must select
visual encodings that highlight the information we want to see. Any sort of
data reduction requires trade-offs. The best visualization choices acknowledge
any difficiencies to a particular visual encoding. By acknowledging these
difficiencies, we can design tools to compensate for their shortcomings while
still maintaining their advantages. Therefore, it is worth first looking at the
possible mappings of data to visual elements. Then, I present commonly used
visual encodings of multi-dimensional continuous data using these mappings.

\subsection{Encoding multi-dimensional data}

Multi-dimensional continuous data consists of a set of continuous ranges, one
for each dimension. In the case of manifold analysis, each of these ranges can
be additionally classified as ``dependent'' or ``independent'' depending on
which side of the mapping they are on. Typical visualization practice is to
give each dimension a separate visual channel. There are a number of possible
visual channels that have been identified.  The ranking of effectiveness of
visual channels (shown in \autoref{tbl:visual_encodings}) was proposed by
Bertin~\cite{Bertin:1967} and confirmed through experiments by Cleveland and
McGill~\cite{Cleveland:1984}, Mackinlay~\cite{Mackinlay:1986}, and Heer and
Bostock~\cite{Heer:2010}.  Munzner~\cite{Munzner:2014} provides a summary of
the results. We are also limited in how many channels we can use
simulataneously. According to Ware~\cite{Ware:2004}, certain channels, such as
red and green are not visually seperable. 

\begin{table}
  \caption{Rankings of visual encodings of quantiative data}
  \label{tbl:visual_encodings}
  \begin{adjustbox}{max width=\linewidth}
  \begin{tabular}{llll}
    Bertin~\cite{Bertin:1967} & Cleveland and McGill~\cite{Cleveland:1984} & Mackinlay~\cite{Mackinlay:1986} & Munzner~\cite{Munzner:2014} \\
     Position & Position along a common scale & Position & Position on common scale \\
     Size & Position along identical, nonaligned scales & Length & Position on unaligned scale \\
     (Grey) Value & Length & Angle & Length (1D size) \\
     Texture & Direction & Slope & Tilt/angle \\
     Color & Angle & Area & Area (2D size) \\
     Orientation & Area & Volume & Depth (3D position) \\
     Shape & Volume & Density & Color luminance\\
     & Curvature & Color saturation & Color saturation \\
     & Densities & Color hue & Curvature \\
     & Shading & & Volume (3D size) \\
     & Color saturation &           & 
  \end{tabular}
  \end{adjustbox}
\end{table}

The difficulty of visualizing a continuous multi-dimensional space on a
two-dimensional screen brings a number of challenges. We treat each dimension
separately, thus, we need several different visual channels. However, there are
simply not enough visual channels available to draw a 15-dimensional object in
a single view. This is further complicated by the fact that separate visual
channels are not necessarilly visually seperable.  Furthermore, each dimension
of the multi-dimensional object under study is treated equally. For example, no
particular axis of a polytope is more important than any other.  We should
encode each dimension using equally weighted effectiveness channels.  With
fewer channels available than data dimensions we either need to reduce the data
or use multiple views to properly visualize the data.


\subsection{Methods}

The common taxonomy of how to view multi-dimensional data on screen is based on
discrete data analysis. There, there are two categories: dimension reduction or
projection. With continuous data, though there is a third possibility, that of
slicing. Therefore, I view the taxonomy of \emph{continuous} multi-dimensional
data analysis methods into two categories. Data-driven methods include both
projection and dimension reduction and reduce the dimensionality of the data
before visualization. View-based methods reduce the data during the
visualization. Slicing is a view-based method.

Purely data-driven methods are commonly known as feature selection or dimension
reduction. The goal is to find a subset of dimensions that are critical to
understanding the dataset. Topological techniques take this a step further.
They discard all spatial information about the dataset and only concentrate on
the difference in function value, as in the Morse-Smale
complex~\cite{Gyulassy:2012a}, or evolution of contours, as in the contour
tree~\cite{Carr:2003a}.  Projections also synthesize the dataset into new
dimensions to show using visual channels. Principal component
analysis~\cite{Holbrey:2006} is a popular choice in this area. This rotates the
space and thus produces new set of dimensions that are a linear combination of
the input dimensions. Even this relatively simple operation (a rotation) can be
difficult to understand. For example, iPCA~\cite{Jeong:2009a} was a tool to
help users understand the effects of the dimensional transformation.

View-based methods try and produce multiple linked views of a multi-dimensional
dataset from different angles. Each view shows a subset of the dimensions.
This way we can use a proper set of visual channels for each view.  We use
interaction to link these different views. These multiple, coordinated, linked
views have been one of the biggest success stories from the visualization
community~\cite{Rao:1994}. The traditional HyperSlice~\cite{Wijk:1993}
technique falls into this category. Each panel of the HyperSlice view shows two
of the input dimensions and the value is encoded with color.
The views are linked through the focus point selection. Changing the focus point
in one sub-plot updates the other sub-plots.

My work focuses on the exploration of the combination of data-driven and
view-based methods.  Data-driven methods reduce the data in a way that we can
get a global overview of the dataset. View-based methods are much more detailed
but can only produce a local view of the data. By combining these methods I can
achieve both a global overview as well as an on-demand local view of the
dataset in a single visualization. 

